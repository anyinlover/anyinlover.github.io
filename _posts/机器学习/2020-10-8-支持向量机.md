---
title: 支持向量机
tags: 机器学习
category: 机器学习
---

支持向量机的数学基础，参考另一篇笔记：

[支持向量机](https://anyinlover.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/SVM/)

要点

- 函数间隔与几何间隔
- 优化问题转化为凸二次函数带线性约束
- 拉格朗日对偶，将多元约束优化问题转化为一元约束优化问题，最大最小值小于等于最小最大值。
- 拉格朗日对偶的 KKT 条件
- 从 KKT 导出支持向量的概念
- 内积的使用
- 核函数的概念和意义
- Mercer 定理，核函数有效的充要条件是核函数矩阵是对称半正定的。
- 针对离群点引入松弛变量。
- 坐标上升法，实质是一次只更新一个参数
- SMO 算法的核心是每次针对一对使 w 增长最快的参数进行更新

支持向量机的编程实现：[scikit 实现](http://scikit-learn.org/stable/modules/svm.html)

对于特征数很多的情况，更容易实现线性分割，推荐使用 linear svc。对于样本数多，特征数少的情况，使用 svc。一般而言，linear svc 运行速度更快。

svc 默认内核使用 rbf，即高斯径向基内核。有参数 gamma，用以调节高斯分布带宽。

支持向量机最重要的参数就是惩罚系统 C，体现了最大间隔与允许误差之间的平衡。
