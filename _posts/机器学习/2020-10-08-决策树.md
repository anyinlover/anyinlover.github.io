---
title: 决策树
tags: 机器学习
category: 机器学习
---

决策树的数学基础

[树 - 木公的博客 | Anyinlover Blog](https://anyinlover.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/tree/)

此外还需参考统计学习方法第五章

要点

- 三种主要的决策树：ID3，C4.5，CART
- 决策树相当于 if-then 规则的集合，集合是互斥和完备的。
- 决策树也能看作是条件概率的分布。
- 通过损失函数最小化来进行学习
- 决策树的生成对应模型的局部选择，决策树的剪枝对应模型的全局选择。
- 通常把信息增益或信息增益比作为特征选择的准则。
- CART 三种衡量不纯度的方法，误分类率，基尼系数，互熵

决策树的编程实现

实际应用中，常常使用决策树的变形，随机森林或者 GBDT。

随机森林相当于决策树的组合

[RandomForests](http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)

GBDT 相当于决策树的迭代

[GBDT（MART） 迭代决策树入门教程 | 简介 - w28971023 的专栏 - 博客频道 - CSDN.NET](https://blog.csdn.net/w28971023/article/details/8240756)
